{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Before Starting\n",
    "\n",
    "For the first point, We started downloading the yellow cab data for January 2018(yellow_tripdata_2018-01.csv). Our plan was to make our studies and analysis firstly for one month and then extend our results considering also other years.\n",
    "Our Data-set contains a really large amount of data so we opted not to choose the simple pd.read_csv() module from pandas. After considering many options such as pandas with the chuncksize option, we decided to use the Dask DataFrames. This different class has some some similarities with the usual Pandas dataframes but has some pros dealing with memory and speed. \n",
    "So the code we used is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('yellow_tripdata_2018-01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking that the import operation ended correctly, we had to merge our datasets with a dataset contained in an HTML page(https://github.com/CriMenghini/ADM-2018/blob/master/Homework_2/taxi_zone_lookup.csv).\n",
    "The data we needed was not the only thing in the page so we searched for a method to be able to extract all the 256 rows with 4 attributes web-scraping the sourcecode. Using the Beautifoul Soup library and with a bit of googling, we found out the correct sintax to find and store all the variables in a new dataset. \n",
    "\n",
    "((((THIS IS FOR US: I DO REALIZE THAT MY CODE PROBABLY IS NOT EFFICIENT BUT IT IS THE ONLY THING I WAS ABLE TO COME UP WITH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get(\"https://github.com/CriMenghini/ADM-2018/blob/master/Homework_2/taxi_zone_lookup.csv\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "ids=[]\n",
    "bor=[]\n",
    "zon=[]\n",
    "srv_zon=[]\n",
    "cell=0\n",
    "for i in range(2,1327,5):    #FIRSTLY We get all the location ids\n",
    "    a=soup.find_all('td')[i].get_text()  \n",
    "    ids.append(a)\n",
    "    cell=cell+1\n",
    "    \n",
    "cell=0\n",
    "for i in range(3,1328,5):    #Then all the boroughs\n",
    "    a=soup.find_all('td')[i].get_text()\n",
    "    bor.append(a)\n",
    "    cell=cell+1\n",
    "    \n",
    "cell=0\n",
    "for i in range(4,1329,5):   #After that we get al zones\n",
    "    a=soup.find_all('td')[i].get_text()\n",
    "    zon.append(a)\n",
    "    cell=cell+1\n",
    "cell=0\n",
    "for i in range(5,1330,5):    #Finally we get all the seving zones\n",
    "    a=soup.find_all('td')[i].get_text()\n",
    "    srv_zon.append(a)\n",
    "    cell=cell+1\n",
    "# after getting all the informations needed we merged all the lists together\n",
    "data_tuples = list(zip(ids,bor,zon,srv_zon)) \n",
    "second=pd.DataFrame(data_tuples, columns=['PULocationID','Borough','Zone','service_zone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceeded merging the two dataframes obtaines(second and df). BUbt first, we converted the Dask DataFrame back to a Pandas One. STILL A LOT OF THINGS CAN BE WRITTEN HERE. I changed all the NaN to 0 because in my opinion they can still be useful for our analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Borough  DOLocationID PULocationID  RatecodeID  VendorID Zone  extra  \\\n",
      "0       0          24.0           41         1.0       1.0    0    0.5   \n",
      "1       0         140.0          239         1.0       1.0    0    0.5   \n",
      "2       0         141.0          262         1.0       1.0    0    0.5   \n",
      "3       0         257.0          140         1.0       1.0    0    0.5   \n",
      "4       0         239.0          246         1.0       1.0    0    0.5   \n",
      "\n",
      "   fare_amount  improvement_surcharge  mta_tax  passenger_count  payment_type  \\\n",
      "0          4.5                    0.3      0.5              1.0           2.0   \n",
      "1         14.0                    0.3      0.5              1.0           2.0   \n",
      "2          6.0                    0.3      0.5              2.0           1.0   \n",
      "3         33.5                    0.3      0.5              1.0           2.0   \n",
      "4         12.5                    0.3      0.5              2.0           1.0   \n",
      "\n",
      "  service_zone store_and_fwd_flag  tip_amount  tolls_amount  total_amount  \\\n",
      "0            0                  N        0.00           0.0          5.80   \n",
      "1            0                  N        0.00           0.0         15.30   \n",
      "2            0                  N        1.00           0.0          8.30   \n",
      "3            0                  N        0.00           0.0         34.80   \n",
      "4            0                  N        2.75           0.0         16.55   \n",
      "\n",
      "  tpep_dropoff_datetime tpep_pickup_datetime  trip_distance  \n",
      "0   2018-01-01 00:24:23  2018-01-01 00:21:05            0.5  \n",
      "1   2018-01-01 01:03:05  2018-01-01 00:44:55            2.7  \n",
      "2   2018-01-01 00:14:21  2018-01-01 00:08:26            0.8  \n",
      "3   2018-01-01 00:52:51  2018-01-01 00:20:22           10.2  \n",
      "4   2018-01-01 00:27:06  2018-01-01 00:09:18            2.5  \n"
     ]
    }
   ],
   "source": [
    "df1 = df.compute()  #Dask datFrame back to pandas\n",
    "frames = [df1,second]\n",
    "result = pd.concat(frames,sort=True)  #Merging\n",
    "result1=result.fillna(value=0)\n",
    "print(result1.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
